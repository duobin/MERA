{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c89f00-d647-4196-9614-f57e87512d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.utils as utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d94902e3-9cb9-477b-a9d7-40adc35fc056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883969e1-0327-401d-94f2-66be7ddc64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c271ae93-51ec-4423-80e4-fee5a698eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = datasets.ImageFolder(\"../../data/train/spectrogram/\", train_transform)\n",
    "validationset = datasets.ImageFolder(\"../../data/validation/spectrogram/\", train_transform)\n",
    "testset = datasets.ImageFolder(\"../../data/test/spectrogram/\", test_transform)\n",
    "\n",
    "trainloader = utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = utils.data.DataLoader(validationset, batch_size=batch_size, shuffle=True)\n",
    "testloader = utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96852dac-5775-4dfb-aa22-eb3c3eed1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32*13*40, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "#         print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "model = AudioNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f3b0de3-1b9e-4246-8895-0e24e955eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b90eaff8-42b1-4d2c-896a-854e3a455463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, trainloader, validationloader, criterion, optimizer, device):\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        vrunning_loss = 0.0\n",
    "#         best_loss = np.Inf\n",
    "        correct = 0.0\n",
    "        vcorrect = 0.0\n",
    "        model.train()\n",
    "        for batch, (data, labels) in enumerate(trainloader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(data)\n",
    "            loss = criterion(output, labels)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, preds = torch.max(output, 1)\n",
    "            correct += torch.sum(preds == labels.data).item()\n",
    "        \n",
    "        model.eval()\n",
    "        for batch, (data, labels) in enumerate(validationloader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "            output = model.forward(data)\n",
    "            loss = criterion(output, labels)\n",
    "            vrunning_loss += loss.item()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            _, preds = torch.max(output, 1)\n",
    "            vcorrect += torch.sum(preds == labels.data).item()\n",
    "            \n",
    "            # accuracy\n",
    "#             if batch%2==best_loss<=running_loss:\n",
    "#                 best_loss = running_loss\n",
    "        taccuracy = 100*(correct/len(trainloader.dataset))\n",
    "        vaccuracy = 100*(vcorrect/len(validationloader.dataset))\n",
    "        print(f\"Epoch: {epoch+1}, Training Loss: {running_loss/len(trainloader.dataset):.4f}, Training Accuracy: {taccuracy:.4f}%\\\n",
    "        Validation Loss: {vrunning_loss/len(validationloader.dataset):.4f}, Validation Accuracy: {vaccuracy:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25d295f4-a617-4dcf-88dd-949b37dc034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testloader, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    correct = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in testloader:\n",
    "            output = model.forward(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            correct += torch.sum(preds == labels.data).item()\n",
    "    accuracy = 100*(correct/len(testloader.dataset))\n",
    "    print(f\"Training Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5571df53-efb7-4efd-abb2-9a2a68b1cc2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martinoywa/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.0428, Training Accuracy: 33.8174%        Validation Loss: 0.0430, Validation Accuracy: 30.9009%\n",
      "Epoch: 2, Training Loss: 0.0426, Training Accuracy: 33.7285%        Validation Loss: 0.0435, Validation Accuracy: 30.9009%\n",
      "Epoch: 3, Training Loss: 0.0425, Training Accuracy: 34.9733%        Validation Loss: 0.0428, Validation Accuracy: 32.8829%\n",
      "Epoch: 4, Training Loss: 0.0425, Training Accuracy: 35.1215%        Validation Loss: 0.0429, Validation Accuracy: 33.6937%\n",
      "Epoch: 5, Training Loss: 0.0422, Training Accuracy: 36.4256%        Validation Loss: 0.0429, Validation Accuracy: 33.2432%\n",
      "Epoch: 6, Training Loss: 0.0420, Training Accuracy: 36.6034%        Validation Loss: 0.0431, Validation Accuracy: 33.7838%\n",
      "Epoch: 7, Training Loss: 0.0419, Training Accuracy: 36.9591%        Validation Loss: 0.0431, Validation Accuracy: 35.3153%\n",
      "Epoch: 8, Training Loss: 0.0417, Training Accuracy: 37.6408%        Validation Loss: 0.0431, Validation Accuracy: 34.1441%\n",
      "Epoch: 9, Training Loss: 0.0414, Training Accuracy: 37.6111%        Validation Loss: 0.0445, Validation Accuracy: 33.3333%\n",
      "Epoch: 10, Training Loss: 0.0412, Training Accuracy: 38.4707%        Validation Loss: 0.0435, Validation Accuracy: 34.1441%\n",
      "Epoch: 11, Training Loss: 0.0413, Training Accuracy: 38.7967%        Validation Loss: 0.0440, Validation Accuracy: 32.0721%\n",
      "Epoch: 12, Training Loss: 0.0405, Training Accuracy: 40.9306%        Validation Loss: 0.0438, Validation Accuracy: 33.1532%\n",
      "Epoch: 13, Training Loss: 0.0401, Training Accuracy: 41.5234%        Validation Loss: 0.0436, Validation Accuracy: 33.0631%\n",
      "Epoch: 14, Training Loss: 0.0391, Training Accuracy: 43.8648%        Validation Loss: 0.0439, Validation Accuracy: 30.4505%\n",
      "Epoch: 15, Training Loss: 0.0383, Training Accuracy: 46.4138%        Validation Loss: 0.0443, Validation Accuracy: 33.6036%\n",
      "Epoch: 16, Training Loss: 0.0363, Training Accuracy: 49.1108%        Validation Loss: 0.0471, Validation Accuracy: 30.7207%\n",
      "Epoch: 17, Training Loss: 0.0338, Training Accuracy: 53.1417%        Validation Loss: 0.0508, Validation Accuracy: 30.2703%\n",
      "Epoch: 18, Training Loss: 0.0305, Training Accuracy: 59.5436%        Validation Loss: 0.0515, Validation Accuracy: 31.3514%\n",
      "Epoch: 19, Training Loss: 0.0257, Training Accuracy: 67.1903%        Validation Loss: 0.0610, Validation Accuracy: 29.8198%\n",
      "Epoch: 20, Training Loss: 0.0210, Training Accuracy: 74.0368%        Validation Loss: 0.0686, Validation Accuracy: 31.3514%\n",
      "Training Accuracy: 31.906614785992215%\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs, trainloader, validationloader, criterion, optimizer, device)\n",
    "test(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e0f7891-4479-42ae-aaad-bcc95a18d711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.55      0.44       347\n",
      "           1       0.19      0.09      0.12       194\n",
      "           2       0.32      0.27      0.29       275\n",
      "           3       0.26      0.22      0.24       212\n",
      "\n",
      "    accuracy                           0.32      1028\n",
      "   macro avg       0.28      0.28      0.27      1028\n",
      "weighted avg       0.30      0.32      0.30      1028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.to(\"cpu\")\n",
    "actual_class = []\n",
    "pred_class = []\n",
    "\n",
    "for (lyrics, label) in testloader:\n",
    "        label, lyrics = label.to(\"cpu\"), lyrics.to(\"cpu\")\n",
    "        with torch.no_grad():\n",
    "            output = model.forward(lyrics)\n",
    "        \n",
    "        actual_class+=label.cpu().numpy().squeeze().tolist()\n",
    "        pred_class+=output.argmax(1).cpu().numpy().squeeze().tolist()\n",
    "        \n",
    "print(classification_report(actual_class, pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f80daae-48ab-4fec-9351-9195ae9f8c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"base.v2.36\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008abb1a-2800-4ed4-9f20-246d0832d39d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd05cbe640e8f412c0cde54cf8960c8ebb69f236f00b3a4ddfc2c3eaa9ee5090602"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
