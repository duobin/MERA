{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### BERT model for music emotion classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# load the data\n",
    "\n",
    "with open(\"../data/train/lyrics/lyrics.txt\", \"r\") as f:\n",
    "    lyrics = f.read()\n",
    "\n",
    "with open(\"../data/train/lyrics/labels.txt\", \"r\") as f:\n",
    "    labels = f.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gently hold our hands Gently hold our heads on high  Aimless time in fear new hide Overthrow the plan Confusion lies in all my words Mad is the soul  We barricade ourselves in holes of temperament This is the dawning of a new age A heart that beats the wrong way Insanity's crescendo  Windcolour, second sight A touch of silence and the violence of dark Illusion span, the aroma of time Shadowlife and the scent of nothingness  Infinite fall of instinct Order of one spells deceit Infin \n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "lyrics_split = lyrics.split(\"\\n\")\n",
    "labels_split = labels.split(\"\\n\")\n",
    "lyrics_split.remove('')\n",
    "labels_split.remove('')\n",
    "\n",
    "print(lyrics_split[0], \"\\n\",labels_split[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Lyrics Quadrant\n0  Gently hold our hands Gently hold our heads on...        1\n1  We are the Sun We are the dead stars We are th...        1\n2  You're out of touch I'm out of time But I'm ou...        0\n3  You finally close the door You've left open wi...        0\n4  Lullaby by birdland that's what I Always hear,...        0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Lyrics</th>\n      <th>Quadrant</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Gently hold our hands Gently hold our heads on...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>We are the Sun We are the dead stars We are th...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You're out of touch I'm out of time But I'm ou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You finally close the door You've left open wi...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lullaby by birdland that's what I Always hear,...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\"Lyrics\": lyrics_split,\n",
    "                     \"Quadrant\": labels_split})\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data[\"Quadrant\"] = pd.to_numeric(data[\"Quadrant\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0    137\n2     76\n1     64\n3     60\nName: Quadrant, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels or quadrants already encoded\n",
    "data[\"Quadrant\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train / Validation Split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                    Lyrics\nQuadrant data_type        \n0        train         116\n         val            21\n1        train          54\n         val            10\n2        train          65\n         val            11\n3        train          51\n         val             9",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Lyrics</th>\n    </tr>\n    <tr>\n      <th>Quadrant</th>\n      <th>data_type</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">0</th>\n      <th>train</th>\n      <td>116</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1</th>\n      <th>train</th>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">2</th>\n      <th>train</th>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">3</th>\n      <th>train</th>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data.index.values,\n",
    "                                                  data.Quadrant.values,\n",
    "                                                  test_size=0.15,\n",
    "                                                  random_state=42,\n",
    "                                                  stratify=data.Quadrant.values)\n",
    "\n",
    "data[\"data_type\"] = [\"not_set\"]*data.shape[0]\n",
    "\n",
    "data.loc[X_train, \"data_type\"] = \"train\"\n",
    "data.loc[X_val, \"data_type\"] = \"val\"\n",
    "data.groupby([\"Quadrant\", \"data_type\"]).count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenize and Encode the Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-f6ad8c941871>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n\u001B[0m\u001B[0;32m      2\u001B[0m                                           do_lower_case=True)\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m encoded_data_train = tokenizer.batch_encode_plus(\n\u001B[0;32m      5\u001B[0m     \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_type\u001B[0m\u001B[1;33m==\u001B[0m\u001B[1;34m\"train\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLyrics\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001B[0m in \u001B[0;36mfrom_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1670\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1671\u001B[0m                 \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1672\u001B[1;33m                     resolved_vocab_files[file_id] = cached_path(\n\u001B[0m\u001B[0;32m   1673\u001B[0m                         \u001B[0mfile_path\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1674\u001B[0m                         \u001B[0mcache_dir\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcache_dir\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001B[0m in \u001B[0;36mcached_path\u001B[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001B[0m\n\u001B[0;32m   1327\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mis_remote_url\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0murl_or_filename\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1328\u001B[0m         \u001B[1;31m# URL, so get it from the cache (downloading if necessary)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1329\u001B[1;33m         output_path = get_from_cache(\n\u001B[0m\u001B[0;32m   1330\u001B[0m             \u001B[0murl_or_filename\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1331\u001B[0m             \u001B[0mcache_dir\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcache_dir\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001B[0m in \u001B[0;36mget_from_cache\u001B[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001B[0m\n\u001B[0;32m   1550\u001B[0m                     )\n\u001B[0;32m   1551\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1552\u001B[1;33m                     raise ValueError(\n\u001B[0m\u001B[0;32m   1553\u001B[0m                         \u001B[1;34m\"Connection error, and we cannot find the requested files in the cached path.\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1554\u001B[0m                         \u001B[1;34m\" Please try again or make sure your Internet connection is on.\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
    "                                          do_lower_case=True)\n",
    "\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    data[data.data_type==\"train\"].Lyrics.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=256,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    data[data.data_type==\"val\"].Lyrics.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=256,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_id_train = encoded_data_train[\"input_ids\"]\n",
    "attention_masks_train = encoded_data_train[\"attention_mask\"]\n",
    "labels_train = torch.tensor(data[data.data_type == \"train\"].Quadrant.values)\n",
    "\n",
    "\n",
    "input_id_val = encoded_data_val[\"input_ids\"]\n",
    "attention_masks_val = encoded_data_val[\"attention_mask\"]\n",
    "labels_val = torch.tensor(data[data.data_type == \"val\"].Quadrant.values)\n",
    "\n",
    "# datasets\n",
    "trainset = TensorDataset(input_id_train, attention_masks_train, labels_train)\n",
    "validationset = TensorDataset(input_id_val, attention_masks_val, labels_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BERT Pre-trained Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=570.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ab35123dc9d48ab8313626826a6ae99"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=440473133.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cf48b1940f441afbd920ac47b156c59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=4,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "trainloader = DataLoader(trainset, sampler=RandomSampler(trainset), batch_size=3)\n",
    "validationloader = DataLoader(validationset, sampler=SequentialSampler(validationset), batch_size=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "epochs = 5\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(trainloader)*epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# performance metrics\n",
    "def f1_score_func(preds, labels):\n",
    "    pred_flat = np.argmax(preds, 1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return f1_score(labels_flat, pred_flat, average=\"weighted\")\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    quadrant_dict = {0: \"Q1\", 1: \"Q2\", 2: \"Q3\", 3: \"Q4\"}\n",
    "\n",
    "    pred_flat = np.argmax(preds, 1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = pred_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        print(f\"Quadrant: {quadrant_dict[label]}\")\n",
    "        print(f\"Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed(seed_val)\n",
    "\n",
    "def evaluate(validation_loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    y_pred, y_true = [], []\n",
    "\n",
    "    for batch in validation_loader:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "            \"labels\": batch[2]\n",
    "                  }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs[\"labels\"].cpu().numpy()\n",
    "        y_pred.append(logits)\n",
    "        y_true.append(label_ids)\n",
    "\n",
    "    loss_avg = total_loss / len(validation_loader)\n",
    "    predictions = np.concatenate(y_pred, axis=0)\n",
    "    true_vals = np.concatenate(y_true, axis=0)\n",
    "\n",
    "    return loss_avg, predictions, true_vals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(trainloader,\n",
    "                        desc=\"Epoch {:1d}\".format(epochs),\n",
    "                        leave=False,\n",
    "                        disable=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "            \"labels\": batch[2]\n",
    "                  }\n",
    "\n",
    "        model.zero_grad()\n",
    "        output = model(**inputs)\n",
    "        loss = output[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"training_loss: {:.3f}\".format(loss.item()/len(batch))})\n",
    "\n",
    "    torch.save(model.state_dict(), f\"finetuned_BERT_epoch_{epoch}.pt\")\n",
    "\n",
    "    tqdm.write(f\"\\nEpoch {epoch}\")\n",
    "\n",
    "    loss_avg = total_loss / len((trainloader))\n",
    "    tqdm.write(f\"Training Loss: {loss_avg}\")\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(validationloader)\n",
    "    val_f1_score = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f\"Validation Loss: {val_loss}\")\n",
    "    tqdm.write(f\"F1 Score (Weighted): {val_f1_score}')\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading and Evalutaion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=4,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"finetuned_BERT_epoch_1.pt\", map_location=\"cpu\"))\n",
    "_, predictions, true_vals = evaluate(validationloader)\n",
    "accuracy_per_class(predictions, true_vals)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resources\n",
    "\n",
    "https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}